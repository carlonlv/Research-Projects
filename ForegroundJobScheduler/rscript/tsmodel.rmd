---
title: "test"
output: html_document
---

```{r}
library("ggplot2")
library("ggfortify")
library("dplyr")
library("forecast")
library("mvtnorm")
library("dict")
```


### Histogram of VMs

```{r}
vmtable <- read.csv("C://Users//carlo//Documents//datasets//vmtable.csv")
header_for_vmtable <- c('vmid','subscriptionid','deploymentid','vmcreated', 'vmdeleted', 'maxcpu', 'avgcpu', 'p95maxcpu', 'vmcategory', 'vmcorecount', 'vmmemory')
names(vmtable) <- header_for_vmtable
vmtable$lifetime = round((vmtable$vmdeleted - vmtable$vmcreated) / 3600)
```

```{r}
hist(vmtable$lifetime, labels = TRUE)
hist(vmtable$lifetime, plot = FALSE)
```


## Impletemt Growing Predictive Model

```{r}
calculate_var_cov_matrix_ar1 <-function(var, l, phi) {
  #### input var: A vector from var(an+l) to var(an+1) of length l
  #### input l: number of prediction
  #### input phi: coeff of AR1 model
  dm=abs(outer(1:l,1:l,"-"))
  var_cov <- matrix(V[outer(1:l,1:l,"pmin")],l,l)*phi^dm
  return(var_cov)
}

do_prediction <- function(model_selection="AR1", last_obs, phi, mean, variance, predict_size, level) {
  if (model_selection == "AR1") {
    # Construct mean
    mu <- rep(last_obs, predict_size)
    mu <- mu * phi^(1:predict_size) + (1 - phi^(1:predict_size)) * mean
    # Construct Var-cov matrix
    var <- cumsum((phi^2)^(0:(predict_size-1)))*variance
    var_cov <- calculate_var_cov_matrix_ar1(var, predict_size, phi)
    # caclulate probability
    up_bound <- rep(level, predict_size)
    lower_bound <- rep(0, predict_size)
    prob <- 1 - pmvnorm(upper = up_bound, lower = lower_bound, mean = mu, sigma = var_cov)
    return(prob)
    
  } else {
    return(NULL)
  }
}

find_pi_upperbound <- function(model_selection='AR1', last_obs, phi, mean, variance, predict_size, prob_cutoff) {
  if (model_selection == "AR1") {
    # Construct mean
    mu <- rep(last_obs, predict_size)
    mu <- mu * phi^(1:predict_size) + (1 - phi^(1:predict_size)) * mean
    var <- rep(variance, predict_size)
    var_cov <- calculate_var_cov_matrix_ar1(var, predict_size, phi)
    upper_bounds <- rep(NA, predict_size)
    for (i in 1:length(upper_bounds)) {
      upper_bounds[i] <- min(mu[i] + qnorm((1-prob_cutoff), 0, 1) * sqrt(var_cov[i,i]), 100)
    }
    return(max(upper_bounds))
    
  } else {
    return(NULL)
  }
}
```


```{r}
mvt_growing_model <- function(dataset, initial_train_size = round(length(dataset) / 4, 1),job_length=5, cpu_required=10, prob_cut_off=0.01, update_freq=1) {
  #### input dataset: N by M matrix, N being number of observations, M being number of time series
  #### input initial_train_size: The number of observations used to train the model
  #### input job_length: The time that the foreground job will be runing
  #### input cpu_required: The cpu that the foreground job requires in percentage
  #### input prob_cut_off: If the probability of background job exceeding 100-cpu_required is smaller than prob_cut_off, then schedule it. Otherwise, don't.
  #### input update_freq: The number of observations for each update of the model, and do the prediction
  
  ## N by M dataframe
  loglikelihood <- data.frame(row.names = 1)
  ## N by M dataframe
  probability <- data.frame(row.names = 1)
  ## N by M dataframe
  predict_result <- data.frame(row.names = 1)
  ## N by M dataframe
  actual_result <- data.frame(row.names = 1)
  ## 4 by M dataframe
  scheduling_summary <- data.frame(matrix(nrow = 4, ncol = ncol(dataset)))
  
  ## Dictionaries
  ts_models <- dict()
  end_time_testing_queue <- numvecdict()
  
  ## Summary Counts
  scheduled_num <- rep(0, ncol(dataset))
  unscheduled_num <- rep(0, ncol(dataset))
  falsely_scheduled_num <- rep(0, ncol(dataset))
  falsely_unscheduled_num <- rep(0, ncol(dataset))
  
  current_end <- initial_train_size
  start_pos <- rep(1, ncol(dataset))
  current_percent <- 0.00
  while (current_end < nrow(dataset)) {
    
    ## Initialize Model and Update Loglikelihood
    loglik <- c()
    prob_vector <- c()
    prediction <- c()
    actual <- c()
    
    for (ts_num in 1:ncol(dataset)) {
      
      ## Update Models
      ts_model <- arima(dataset[start_pos[ts_num]:current_end, ts_num], order = c(1,0,0), include.mean = TRUE)
      ts_models[[ts_num]] <- ts_model
      
      ## Find Loglikelihood
      loglik[ts_num] <- ts_model$loglik
      
      ## Schedule the job
      last_obs <- dataset[current_end, ts_num]
      prob_vector[ts_num] <- do_prediction(last_obs = last_obs, phi = ts_model$coef[1], mean = ts_model$coef[2], predict_size = job_length, level = (100 - cpu_required))[job_length]
      if (prob_vector[ts_num] < prob_cut_off) {
        prediction[ts_num] <- 1
        scheduled_num[ts_num] <- scheduled_num[ts_num] + 1
      } else {
        prediction[ts_num] <- 0
        unscheduled_num[ts_num] <- unscheduled_num[ts_num] + 1
      }
      
      
      ## Check correctness of previous schedulings
      if (length(end_time_testing_queue[[current_end]]) != 0) {
        info_lst <- end_time_testing_queue[[current_end]]
        lst_len <- length(info_lst)
        for (i in seq(1, lst_len, 3)) {
          start_time <- info_lst[i]
          end_time <- info_lst[i+1]
          row_num <- info_lst[i+2]
          
          position_vec <- dataset[start_time:end_time, ts_num]
          if (all(position_vec < (100 - cpu_required))) {
            actual[ts_num] <- 1
            if (predict_result[row_num, ts_num] == 0) {
              falsely_unscheduled_num[ts_num] <- falsely_unscheduled_num[ts_num] + 1
            }
          } else {
            actual[ts_num] <- 0
            if (predict_result[row_num, ts_num] == 1) {
              falsely_scheduled_num[ts_num] <- falsely_scheduled_num[ts_num] + 1
            }
          } 
        }
      }
    }
    
    ## Store Loglikelihood v
    loglikelihood <- rbind(loglikelihood, loglik)
    ## Store probability
    probability <- rbind(probability, prob_vector)
    ## Store Prediction
    predict_result <- rbind(predict_result, prediction)
    ## Store Actual
    actual_result <- rbind(actual_result, actual)
    
    ## Queue the jobs to check their correctness later
    closest_update <- current_end + ceiling(job_length / update_freq) * update_freq
    end_time_testing_queue$append_number(closest_update, current_end + 1)
    end_time_testing_queue$append_number(closest_update, current_end + job_length)
    end_time_testing_queue$append_number(closest_update, nrow(predict_result))
    
    ## Update current_end
    current_end <- current_end + update_freq
    if (current_percent != round((current_end - initial_train_size) / (nrow(dataset) - initial_train_size), digits = 2)) {
      print(current_percent)
      current_percent <- round((current_end - initial_train_size) / (nrow(dataset) - initial_train_size), digits = 2)
    }
  }
  
  ## Change column and row names, N by M
  colnames(loglikelihood) <- colnames(dataset)
  rownames(loglikelihood) <- seq(initial_train_size, initial_train_size + update_freq * (nrow(loglikelihood) - 1), update_freq)
  
  colnames(probability) <- colnames(dataset)
  rownames(probability) <- seq(initial_train_size + 1, initial_train_size + 1 + update_freq * (nrow(probability) - 1), update_freq)
  
  colnames(predict_result) <- colnames(dataset)
  rownames(predict_result) <- seq(initial_train_size + 1, initial_train_size + 1 + update_freq * (nrow(predict_result) - 1), update_freq)
  
  colnames(actual_result) <- colnames(dataset)
  rownames(actual_result) <- seq(initial_train_size + 1, initial_train_size + 1 + update_freq * (nrow(actual_result) - 1), update_freq)
  
  colnames(scheduling_summary) <- colnames(dataset)
  scheduling_summary[1,] <- scheduled_num
  scheduling_summary[2,] <- unscheduled_num
  scheduling_summary[3,] <- falsely_scheduled_num
  scheduling_summary[4,] <- falsely_unscheduled_num
  rownames(scheduling_summary) <- c('Scheduled_Num', 'Unscheduled_Num', 'Falsly_scheduled_Num', 'Falsely_unscheduled_Num')
  
  result <- list('loglik' = loglikelihood, 'prob' = probability, 'predict' = predict_result, 'actual' = actual_result, 'scheduling_summary' = scheduling_summary)
  
  return(result)
}
```

```{r}
mvt_stationary_model <- function(dataset, initial_train_size = round(length(dataset) / 4, 1),job_length=5, cpu_required=rep(10, ncol(dataset)), prob_cut_off=0.01, update_freq=1) {
  #### input dataset: N by M matrix, N being number of observations, M being number of time series
  #### input initial_train_size: The number of first observations used to train the model
  #### input job_length: The time that the foreground job will be runing
  #### input cpu_required: A vector, the cpu that the foreground job requires in percentage
  #### input prob_cut_off: If the probability of background job exceeding 100-cpu_required is smaller than prob_cut_off, then schedule it. Otherwise, don't.
  #### input update_freq: The number of observations for each update of the model, and do the prediction
  
  ## N by M dataframe
  probability <- data.frame(row.names = 1)
  ## N by M dataframe
  predict_result <- data.frame(row.names = 1)
  ## N by M dataframe
  actual_result <- data.frame(row.names = 1)
  ## 4 by M dataframe
  scheduling_summary <- data.frame(matrix(nrow = 4, ncol = ncol(dataset)))
  
  ## Dictionaries
  ts_models <- dict()
  end_time_testing_queue <- numvecdict()
  
  ## Summary Counts
  scheduled_num <- rep(0, ncol(dataset))
  unscheduled_num <- rep(0, ncol(dataset))
  falsely_scheduled_num <- rep(0, ncol(dataset))
  falsely_unscheduled_num <- rep(0, ncol(dataset))
  
  
  ## Train Model
  coeffs <- rep(NA, ncol(dataset))
  means <- rep(NA, ncol(dataset))
  for (ts_num in 1:ncol(dataset)) {
    ts_model <- arima(dataset[1:initial_train_size, ts_num], order = c(1,0,0), include.mean = TRUE)
    ts_models[[ts_num]] <- ts_model
    coeffs[ts_num] <- as.numeric(ts_model$coef[1])
    means[ts_num] <- as.numeric(ts_model$coef[2])
  }
  current_end <- initial_train_size
  current_percent <- 0.00
  while (current_end < nrow(dataset)) {
    
    ## Initialize Model 
    prob_vector <- c()
    prediction <- c()
    actual <- c()
    
    for (ts_num in 1:ncol(dataset)) {
      
      ## Schedule the job
      last_obs <- dataset[current_end, ts_num]
      ts_model <- ts_models[[ts_num]] 
      prob_vector[ts_num] <- do_prediction(last_obs = last_obs, phi = ts_model$coef[1], mean = ts_model$coef[2], predict_size = job_length, level = (100 - cpu_required[ts_num]))[job_length]
      if (prob_vector[ts_num] < prob_cut_off) {
        prediction[ts_num] <- 1
        scheduled_num[ts_num] <- scheduled_num[ts_num] + 1
      } else {
        prediction[ts_num] <- 0
        unscheduled_num[ts_num] <- unscheduled_num[ts_num] + 1
      }
      
      ## Check correctness of previous schedulings
      if (length(end_time_testing_queue[[current_end]]) != 0) {
        info_lst <- end_time_testing_queue[[current_end]]
        lst_len <- length(info_lst)
        for (i in seq(1, lst_len, 3)) {
          start_time <- info_lst[i]
          end_time <- info_lst[i+1]
          row_num <- info_lst[i+2]
          
          position_vec <- dataset[start_time:end_time, ts_num]
          if (all(position_vec < (100 - cpu_required[ts_num]))) {
            actual[ts_num] <- 1
            if (predict_result[row_num, ts_num] == 0) {
              falsely_unscheduled_num[ts_num] <- falsely_unscheduled_num[ts_num] + 1
            }
          } else {
            actual[ts_num] <- 0
            if (predict_result[row_num, ts_num] == 1) {
              falsely_scheduled_num[ts_num] <- falsely_scheduled_num[ts_num] + 1
            }
          } 
        }
      }
    }
    
    ## Store probability
    probability <- rbind(probability, prob_vector)
    ## Store Prediction
    predict_result <- rbind(predict_result, prediction)
    ## Store Actual
    actual_result <- rbind(actual_result, actual)
    
    ## Queue the jobs to check their correctness later
    closest_update <- current_end + ceiling(job_length / update_freq) * update_freq
    end_time_testing_queue$append_number(closest_update, current_end + 1)
    end_time_testing_queue$append_number(closest_update, current_end + job_length)
    end_time_testing_queue$append_number(closest_update, nrow(predict_result))
    
    ## Update current_end
    current_end <- current_end + update_freq
    if (current_percent != round((current_end - initial_train_size) / (nrow(dataset) - initial_train_size), digits = 2)) {
      print(current_percent)
      current_percent <- round((current_end - initial_train_size) / (nrow(dataset) - initial_train_size), digits = 2)
    }
  }
  
  ## Change column and row names, N by M
  colnames(probability) <- colnames(dataset)
  rownames(probability) <- seq(initial_train_size + 1, initial_train_size + 1 + update_freq * (nrow(probability) - 1), update_freq)
  
  colnames(predict_result) <- colnames(dataset)
  rownames(predict_result) <- seq(initial_train_size + 1, initial_train_size + 1 + update_freq * (nrow(predict_result) - 1), update_freq)
  
  colnames(actual_result) <- colnames(dataset)
  rownames(actual_result) <- seq(initial_train_size + 1, initial_train_size + 1 + update_freq * (nrow(actual_result) - 1), update_freq)
  
  colnames(scheduling_summary) <- colnames(dataset)
  scheduling_summary[1,] <- scheduled_num
  scheduling_summary[2,] <- unscheduled_num
  scheduling_summary[3,] <- falsely_scheduled_num
  scheduling_summary[4,] <- falsely_unscheduled_num
  rownames(scheduling_summary) <- c('Scheduled_Num', 'Unscheduled_Num', 'Falsly_scheduled_Num', 'Falsely_unscheduled_Num')
  
  result <- list('prob' = probability, 'predict' = predict_result, 'actual' = actual_result, 'scheduling_summary' = scheduling_summary)
  
  return(result)
}
```


## Analysis on Sample Job 1

```{r}
vmjob1 <- read.csv("C://Users//carlo//Documents//datasets//csvalldata//1227464.csv")
```

\textbf{1. Time Series Plot}

```{r}
ts_model1 <- ts(data = vmjob1$max_cpu, start = 0, frequency = 288)
autoplot(ts_model1) + 
  ggtitle("Figure 1. Time Series Plot of Job 1") + 
  ylab("Cpu Occupancy") + 
  xlab("Timestamp") +
  theme(plot.title = element_text(size=8, face="bold"))
```


## Analysis on Sample Job 2

```{r}
vmjob2 <- read.csv("C://Users//carlo//Documents//datasets//csvalldata//1926479.csv")
```

\textbf{1. Time Series Plot}

```{r}
ts_model2 <- ts(data = vmjob2$max_cpu, start = 0, frequency = 288)
autoplot(ts_model2) + 
  ggtitle("Figure 2. Time Series Plot of Job 2") + 
  ylab("Cpu Occupancy") + 
  xlab("Timestamp") +
  theme(plot.title = element_text(size=8, face="bold"))
```
